beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Likelihood function
for (i in 1:N){
MBHtrue[i]~dnorm(MBH[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.b <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
meanx ~ dgamma(30,3)
varx ~ dgamma(2,1)
for (i in 1:N){
#MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.c <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
for (i in 1:N){
MBHtrue[i]~dunif(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.d <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
meanx ~ dgamma(30,3)
varx ~ dgamma(2,1)
for (i in 1:N){
# MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
}
}"
inits <- list(beta.0=0,beta.1=0,size=0.1)
params <- c("beta.0","beta.1","size","prediction.NB","MBHtrue")
jags.neg.a <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.a),
n.chains = 3,
n.adapt=1000
)
jags.neg.b <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.b),
n.chains = 3,
n.adapt=1000
)
jags.neg.c <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.c),
n.chains = 3,
n.adapt=1000
)
jags.neg.d <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.d),
n.chains = 3,
n.adapt=1000
)
jagssamples.nb.a <- jags.samples(jags.neg.a, params, n.iter = 1000)
jagssamples.nb.b <- jags.samples(jags.neg.b, params, n.iter = 1000)
jagssamples.nb.c <- jags.samples(jags.neg.c, params, n.iter = 1000)
jagssamples.nb.d <- jags.samples(jags.neg.d, params, n.iter = 1000)
names(jagssamples.nb.a)
summary(as.mcmc.list(jagssamples.nb.a$beta.0))
summary(as.mcmc.list(jagssamples.nb.a$beta.1))
summary(as.mcmc.list(jagssamples.nb.a$size))
sMBHtrue.a = summary(as.mcmc.list(jagssamples.nb.a$MBHtrue))
MBHtrue.a = sMBHtrue.a$statistics[,"Mean"]
predN.a = summary(as.mcmc.list(jagssamples.nb.a$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.b$beta.0))
summary(as.mcmc.list(jagssamples.nb.b$beta.1))
sMBHtrue.b = summary(as.mcmc.list(jagssamples.nb.b$MBHtrue))
MBHtrue.b = sMBHtrue.b$statistics[,"Mean"]
predN.b = summary(as.mcmc.list(jagssamples.nb.b$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.c$beta.0))
summary(as.mcmc.list(jagssamples.nb.c$beta.1))
sMBHtrue.c = summary(as.mcmc.list(jagssamples.nb.c$MBHtrue))
MBHtrue.c = sMBHtrue.c$statistics[,"Mean"]
predN.c = summary(as.mcmc.list(jagssamples.nb.c$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.d$beta.0))
summary(as.mcmc.list(jagssamples.nb.d$beta.1))
sMBHtrue.d = summary(as.mcmc.list(jagssamples.nb.d$MBHtrue))
MBHtrue.d = sMBHtrue.d$statistics[,"Mean"]
predN.d = summary(as.mcmc.list(jagssamples.nb.d$prediction.NB))$statistics[,"Mean"]
plot(GCS$MBH, MBHtrue.a, col="blue")
points(GCS$MBH, MBHtrue.b, col="red")
points(GCS$MBH, MBHtrue.c, col="green")
points(GCS$MBH, MBHtrue.d, col="orange")
abline(a=0,b=1)
s = order(GCS$MBH)
plot(GCS$MBH[s], log(GCS$N_GC)[s])
points(GCS$MBH[s], log(predN.a)[s], col="blue", type="o") # way off
points(GCS$MBH[s], log(predN.b)[s], col="red", type="o")
points(GCS$MBH[s], log(predN.c)[s], col="green", type="o")
points(GCS$MBH[s], log(predN.d)[s], col="orange", type="o")
plot(MBHtrue.a, log(predN.a))
plot(MBHtrue.b, log(predN.b))
plot(MBHtrue.c, log(predN.c))
plot(MBHtrue.d, log(predN.d))
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/COINtoolbox/NB_GCs/Tutorial")
# compare different error models for negbin
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
dim(GCS)
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
err_sig_e<-GCS$err_sig_e
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH
)
model.NB.a <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Likelihood function
for (i in 1:N){
MBHtrue[i]~dnorm(MBH[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.b <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
meanx ~ dgamma(30,3)
varx ~ dgamma(2,1)
for (i in 1:N){
#MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.c <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
for (i in 1:N){
MBHtrue[i]~dunif(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
prediction.NB[i]~dnegbin(p[i],size)
}
}"
model.NB.d <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
meanx ~ dgamma(30,3)
varx ~ dgamma(2,1)
for (i in 1:N){
# MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
}
}"
inits <- list(beta.0=0,beta.1=0,size=0.1)
params <- c("beta.0","beta.1","size","prediction.NB","MBHtrue")
jags.neg.a <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.a),
n.chains = 3,
n.adapt=1000
)
jags.neg.b <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.b),
n.chains = 3,
n.adapt=1000
)
jags.neg.c <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.c),
n.chains = 3,
n.adapt=1000
)
jags.neg.d <- jags.model(
data = jags.data,
inits = inits,
textConnection(model.NB.d),
n.chains = 3,
n.adapt=1000
)
jagssamples.nb.a <- jags.samples(jags.neg.a, params, n.iter = 1000)
jagssamples.nb.b <- jags.samples(jags.neg.b, params, n.iter = 1000)
jagssamples.nb.c <- jags.samples(jags.neg.c, params, n.iter = 1000)
jagssamples.nb.d <- jags.samples(jags.neg.d, params, n.iter = 1000)
names(jagssamples.nb.a)
summary(as.mcmc.list(jagssamples.nb.a$beta.0))
summary(as.mcmc.list(jagssamples.nb.a$beta.1))
summary(as.mcmc.list(jagssamples.nb.a$size))
sMBHtrue.a = summary(as.mcmc.list(jagssamples.nb.a$MBHtrue))
MBHtrue.a = sMBHtrue.a$statistics[,"Mean"]
predN.a = summary(as.mcmc.list(jagssamples.nb.a$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.b$beta.0))
summary(as.mcmc.list(jagssamples.nb.b$beta.1))
sMBHtrue.b = summary(as.mcmc.list(jagssamples.nb.b$MBHtrue))
MBHtrue.b = sMBHtrue.b$statistics[,"Mean"]
predN.b = summary(as.mcmc.list(jagssamples.nb.b$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.c$beta.0))
summary(as.mcmc.list(jagssamples.nb.c$beta.1))
sMBHtrue.c = summary(as.mcmc.list(jagssamples.nb.c$MBHtrue))
MBHtrue.c = sMBHtrue.c$statistics[,"Mean"]
predN.c = summary(as.mcmc.list(jagssamples.nb.c$prediction.NB))$statistics[,"Mean"]
summary(as.mcmc.list(jagssamples.nb.d$beta.0))
summary(as.mcmc.list(jagssamples.nb.d$beta.1))
sMBHtrue.d = summary(as.mcmc.list(jagssamples.nb.d$MBHtrue))
MBHtrue.d = sMBHtrue.d$statistics[,"Mean"]
predN.d = summary(as.mcmc.list(jagssamples.nb.d$prediction.NB))$statistics[,"Mean"]
plot(GCS$MBH, MBHtrue.a, col="blue")
points(GCS$MBH, MBHtrue.b, col="red")
points(GCS$MBH, MBHtrue.c, col="green")
points(GCS$MBH, MBHtrue.d, col="orange")
abline(a=0,b=1)
s = order(GCS$MBH)
plot(GCS$MBH[s], log(GCS$N_GC)[s])
points(GCS$MBH[s], log(predN.a)[s], col="blue", type="o") # way off
points(GCS$MBH[s], log(predN.b)[s], col="red", type="o")
points(GCS$MBH[s], log(predN.c)[s], col="green", type="o")
points(GCS$MBH[s], log(predN.d)[s], col="orange", type="o")
plot(MBHtrue.a, log(predN.a))
plot(MBHtrue.b, log(predN.b))
plot(MBHtrue.c, log(predN.c))
plot(MBHtrue.d, log(predN.d))
plot(MBHtrue.a, log(predN.a))
plot(MBHtrue.b, log(predN.b))
plot(MBHtrue.c, log(predN.c))
plot(MBHtrue.d, log(predN.d))
plot(GCS$MBH[s], log(GCS$N_GC)[s])
points(GCS$MBH[s], log(predN.a)[s], col="blue", type="o") # way off
points(GCS$MBH[s], log(predN.b)[s], col="red", type="o")
points(GCS$MBH[s], log(predN.c)[s], col="green", type="o")
points(GCS$MBH[s], log(predN.d)[s], col="orange", type="o")
plot(MBHtrue.d, log(predN.d))
points(GCS$MBH[s], log(predN.d)[s], col="orange", type="o")
s = order(GCS$MBH)
plot(GCS$MBH[s], log(GCS$N_GC)[s])
points(GCS$MBH[s], log(predN.a)[s], col="blue", type="o") # way off
points(GCS$MBH[s], log(predN.b)[s], col="red", type="o")
points(GCS$MBH[s], log(predN.c)[s], col="green", type="o")
points(GCS$MBH[s], log(predN.d)[s], col="orange", type="o")
plot(MBHtrue.a, log(predN.a))
plot(MBHtrue.b, log(predN.b))
plot(MBHtrue.c, log(predN.c))
plot(MBHtrue.d, log(predN.d))
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/COINtoolbox/NB_GCs/Tutorial")
#Poisson and NB regression using JAGS by Rafael S. de Souza
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Function to allow parse labels in facet_wrap
facet_wrap_labeller <- function(gg.plot,labels=NULL) {
#works with R 3.0.1 and ggplot2 0.9.3.1
require(gridExtra)
g <- ggplotGrob(gg.plot)
gg <- g$grobs
strips <- grep("strip_t", names(gg))
for(ii in seq_along(labels))  {
modgrob <- getGrob(gg[[strips[ii]]], "strip.text",
grep=TRUE, global=TRUE)
gg[[strips[ii]]]$children[[modgrob$name]] <- editGrob(modgrob,label=labels[ii])
}
g$grobs <- gg
class(g) = c("arrange", "ggplot",class(g))
g
}
give.n <- function(x){
return(c(y = 0.5, label = length(x)))
# experiment with the multiplier to find the perfect position
}
################
# Read data
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
dim(GCS)
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
err_sig_e<-GCS$err_sig_e
jags.data3 <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH
#  meanx = mean(GCS$MBH),
#  varx = var (GCS$MBH)
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
meanx ~ dgamma(30,3)
varx ~ dgamma(2,1)
for (i in 1:N){
#MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(5,12)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]+exp(errorN[i]-errN_GC[i])
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
}
}"
inits3 <- list(beta.0=0,beta.1=0,size=0.1)
params3 <- c("beta.0","beta.1","size","prediction.NB","MBHtrue")
jags.neg3 <- jags.model(
data = jags.data3,
inits = inits3,
textConnection(model.NB),
n.chains = 3,
n.adapt=1000
)
update(jags.neg3, 10000)
jagssamples.nb3 <- jags.samples(jags.neg3, params3, n.iter = 50000)
codasamples.nb3 <- coda.samples(jags.neg3, params3, n.iter = 50000)
summary(as.mcmc.list(jagssamples.nb3$beta.0))
summary(as.mcmc.list(jagssamples.nb3$beta.1))
summary(as.mcmc.list(jagssamples.nb3$size))
MBHtrue<-summary(as.mcmc.list(jags.samples(jags.neg3, params3, n.iter = 50000)$MBHtrue),quantiles=0.5)
pred.NBerr<-summary(as.mcmc.list(jagssamples.nb3$prediction.NB),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.NB2err<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,MBHtrue=MBHtrue$quantiles,MBH=GCS$MBH,mean=pred.NBerr$statistics[,1],lwr1=pred.NBerr$quantiles[,3],lwr2=pred.NBerr$quantiles[,2],lwr3=pred.NBerr$quantiles[,1],upr1=pred.NBerr$quantiles[,5],upr2=pred.NBerr$quantiles[,6],upr3=pred.NBerr$quantiles[,7])
S.NB1<-ggs(codasamples.nb3 ,family=c("beta"))
S.NB2<-ggs(codasamples.nb3,family=c("size"))
S.NB<-rbind(S.NB1,S.NB2,deparse.level=2)
S.NB$Parameter<-revalue(S.NB$Parameter, c("beta.0"=expression(beta[0]), "beta.1"=expression(beta[1]),
"size"="k"))
ggs_density(S.NB)+
scale_colour_economist(guide="none")+
theme_hc()+
scale_fill_economist()+
#  theme_economist_white(gray_bg = F, base_size = 11, base_family = "sans")+
theme(strip.background = element_rect(fill="gray95"),plot.background = element_rect(fill = 'white', colour = 'white'),
legend.position="none",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),axis.text.x=element_text(size=25),
strip.text.x=element_text(size=25),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=25))+xlab("Parameter  value")+ylab("Density")
ggplot(pred.NB2err,aes(x=MBH,y=NGC))+
geom_ribbon(aes(x=MBHtrue,y=mean,ymin=lwr1, ymax=upr1), alpha=0.3, fill="gray") +
geom_ribbon(aes(x=MBHtrue,y=mean,ymin=lwr2, ymax=upr2), alpha=0.2, fill="gray") +
geom_ribbon(aes(x=MBHtrue,y=mean,ymin=lwr3, ymax=upr3), alpha=0.1, fill="gray") +
geom_point(aes(colour=Type,shape=Type),size=3.25)+
geom_errorbar(guide="none",aes(colour=Type,ymin=NGC-N_err,ymax=NGC+N_err),alpha=0.7)+
geom_errorbarh(guide="none",aes(colour=Type,xmin=MBH-GCS$lowMBH,
xmax=MBH+upMBH),alpha=0.7)+
geom_line(aes(x=MBHtrue,y=mean),colour="gray25",linetype="dashed",size=1.2)+
scale_y_continuous(trans = 'log10',breaks=trans_breaks("log10",function(x) 10^x),
labels=trans_format("log10",math_format(10^.x)))+
scale_colour_gdocs()+
scale_shape_manual(values=c(19,2,8))+
#  theme_economist_white(gray_bg = F, base_size = 11, base_family = "sans")+
theme_hc()+
ylab(expression(N[GC]))+
xlab(expression(log~M[BH]/M['\u0298']))+theme(legend.position="top",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=25))
exp(-1.15)
0.3166368/(1+0.3166368)
32/100
exp(1.5)
exp(1.05)/(1+exp(1.05))
