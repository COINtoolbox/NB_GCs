
---
title: "GCS analysis"
author: "Bart Buelens, Rafael S. de Souza"
date: "December 6, 2014"
output: html_document
---

This document contains some preliminary work possibly of use to a paper by the COIN group on negative binomial distributions to model count data.

It is put together in RStudio as a Rmd file from which a PDF is easily generated.

# Introduction
The catalog of Globular Cluster Systems (GCS) presented in Harris et al. 2013 is analyzed. In particular, three statistical models relating the number of GCSs to the dynamical mass of galaxies are studied. These include a linear model assuming gaussianity, and generalized linear models assuming poisson and negative binomial distributions.
At the end the analysis is repeated using the black hole mass instead of the dynamical mass.

# Data
The data set 'GCs.csv' sent by e-mail by Rafael on Dec 1st is used.
``` {r Read data}
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
dim(GCS)
```
Of the initial 422 galaxies in the catalog, 45 are retained for which variables needed here are present. The errors are used further down. Weights are defined to be the inverse of the error.
``` {r Weights}
GCS$w = 1/ GCS$N_GC_err
```
It is somewhat strange that in the catalogue the GCS count is not always integer; an integer version is derived here simply by rounding.
* NOTE: in Rafas file these are integer! *

Before proceding some useful libraries are loaded.
``` {r Libraries}
library(ggplot2)
library(MASS)     # glm.nb
library(COUNT)   # diagnostics
library(lmtest)
library(gamlss.tr)

```

# Modeling
The first way to model counts is using a linear model for the log counts. The second is a glm poisson model, the third is a glm with negative binomial. These are specified and fitted as follows.
``` {r Fit models}
linmFit = glm(log(N_GC) ~ Mdyn, family="gaussian",GCS)
poisFit = glm(N_GC ~ Mdyn, GCS, family="poisson")
negbFit = glm.nb(N_GC ~ Mdyn, GCS)
```
The results are now plotted using ggplot() from the ggplot2 package.
``` {r}
X = GCS[,c("Galaxy","Mdyn","N_GC")]
X = rbind(X,X,X,X)
X$method = factor(rep(c("obs","linm","pois","negb"),each=nrow(GCS)))
X[X$method == "linm","N_GC"] = exp(linmFit$fitted.values)
X[X$method == "pois","N_GC"] = poisFit$fitted.values
X[X$method == "negb","N_GC"] = negbFit$fitted.values
ggplot(X, aes(x = Mdyn,y=log(N_GC))) + 
   geom_point(aes(colour=method), data = subset(X, method=="obs")) + 
   geom_line(aes(colour=method), data = subset(X, method != "obs")) 
``` 
The three are not dramatically different. 

# Model comparison
A quantitative comparison is obtained using leave-one-out cross validation (LOO-CV). Each observation is left out once and predicted using a model fit on the other data. The errors are the differences between the predictions and true values. The squared differences are weighted using the weights derived earlier, inversely proportional to the errors on the known values. LOO-CV is implemented as follows.
``` {r "LOO calculation"}
N = nrow(GCS)
A = data.frame(linm=rep(NA,N))
A$negb = A$pois = NA
for (i in 1:N) {
   Gx = GCS[-i,]
   f1 = lm(log(N_GC) ~ Mdyn, Gx)
   f2 = glm(N_GC ~ Mdyn, Gx, family="poisson")
   f3 = glm.nb(N_GC ~ Mdyn, Gx)
   A[i,"linm"] = GCS$w[i] * (GCS$N_GC[i] - exp(predict(f1, GCS[i,])))^2
   A[i, "pois"] = GCS$w[i] * (GCS$N_GC[i] - predict(f2, GCS[i,]))^2   
   A[i, "negb"] = GCS$w[i] * (GCS$N_GC[i] - predict(f3, GCS[i,]))^2   
}
``` 
The square root of the mean of the values in A gives the LOO-CV measure.
``` {r LOO result}
lapply(A, function(x) sqrt(mean(x)))
``` 
Based on the LOO-CV criterion, the linear model is best. In this case there is no benefit in using Poisson or negative binomial models. 




# Black hole mass
The same analysis now using the black hole mass as predictor rather than dynamical mass.

``` {r}
linmFit = lm(log(N_GC) ~ MBH, GCS)
gaussFit = glm(log(N_GC) ~ MBH, family="gaussian",GCS)
poisFit = glm(N_GC ~MBH, GCS, family="poisson")
negbFit = glm.nb(N_GC ~ MBH, GCS)
gen.trun(0,"NBI",type="left",name="lefttr")
trunFit=gamlss(N_GC ~ MBH, data=na.omit(GCS),family=NBIlefttr)
X = GCS[,c("Galaxy","MBH","N_GC")]
X = rbind(X,X,X,X,X)
X$method = factor(rep(c("obs","linm","gauss","pois","negb"),each=nrow(GCS)))
X[X$method == "linm","N_GC"] = exp(linmFit$fitted.values)
X[X$method == "gauss","N_GC"] = exp(gaussFit$fitted.values)
X[X$method == "pois","N_GC"] = poisFit$fitted.values
X[X$method == "negb","N_GC"] = negbFit$fitted.values
ggplot(X, aes(x = MBH,y=log(N_GC))) + 
   geom_point(aes(colour=method), data = subset(X, method=="obs")) + 
   geom_line(aes(colour=method), data = subset(X, method != "obs"))
A = data.frame(linm=rep(NA,N))
A$negb = A$pois = A$gauss= NA
for (i in 1:N) {
   Gx = GCS[-i,]
   f1 = lm(log(N_GC) ~ MBH, Gx)
   f2 = glm(log(N_GC) ~ MBH, family="gaussian",Gx)
   f3 = glm(N_GC ~ MBH, Gx, family="poisson")
   f4 = glm.nb(N_GC ~ MBH, Gx)
   A[i,"linm"] = GCS$w[i] * (GCS$N_GC[i] - exp(predict(f1, GCS[i,])))^2
   A[i,"gauss"] = GCS$w[i] * (GCS$N_GC[i] - exp(predict(f2, GCS[i,])))^2
   A[i, "pois"] = GCS$w[i] * (GCS$N_GC[i] - predict(f3, GCS[i,]))^2   
   A[i, "negb"] = GCS$w[i] * (GCS$N_GC[i] - predict(f4, GCS[i,]))^2   
}
lapply(A, function(x) sqrt(mean(x)))
```

# 10-fold cross validation
```{r}
require(caret)
folds <- createFolds(GCS$N_GC, k=10)
A = data.frame(linm=rep(NA,N))
A$negb = A$pois = A$gauss= NA
for (i in 1:10) {
   Gx = GCS[-folds[[i]],]
   f1 = lm(log(N_GC) ~ MBH, Gx)
   f2 = glm(log(N_GC) ~ MBH, family="gaussian",Gx)
   f3 = glm(N_GC ~ MBH, Gx, family="poisson")
   f4 = glm.nb(N_GC ~ MBH, Gx)
   A[folds[[i]],"linm"] = GCS$w[folds[[i]]] * (GCS$N_GC[folds[[i]]] - exp(predict(f1, GCS[folds[[i]],])))^2
   A[folds[[i]],"gauss"] = GCS$w[folds[[i]]] * (GCS$N_GC[folds[[i]]] - exp(predict(f2, GCS[folds[[i]],])))^2
   A[folds[[i]], "pois"] = GCS$w[folds[[i]]] * (GCS$N_GC[folds[[i]]] - predict(f3, GCS[folds[[i]],]))^2   
   A[folds[[i]], "negb"] = GCS$w[folds[[i]]] * (GCS$N_GC[folds[[i]]] - predict(f4, GCS[folds[[i]],]))^2   
}
lapply(A, function(x) sqrt(mean(x)))
```

# Errors for GLM  Prediction

``` {r}
pred_glm<-function(x){
preds <- predict(x, type = "link", se.fit = TRUE)
critval <- 1.96 ## approx 95% CI
upr <- preds$fit + (critval * preds$se.fit)
lwr <- preds$fit - (critval * preds$se.fit)
fit <- preds$fit

fit2 <- x$family$linkinv(fit)
upr2 <- x$family$linkinv(upr)
lwr2 <- x$family$linkinv(lwr)
errup<-upr2-fit2
errlow<-fit2-lwr2
return(list(fit=fit2,lwr=lwr2,upr=upr2,errlow =errlow,errup=errup))
}
```



# Goodness of fit 

``` {r}
 1 - pchisq(summary(gaussFit)$deviance,summary(gaussFit)$df.residual)
 1 - pchisq(summary(poisFit)$deviance,summary(poisFit)$df.residual)
 1 - pchisq(summary(negbFit)$deviance,summary(negbFit)$df.residual)
````


# References

Harris, W.E., Harris, G.L.H., and Alessi, M. 2013, ApJ 772, 82.
 


 