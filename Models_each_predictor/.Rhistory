system("defaults write org.R-project.R force.LANG en_US.UTF-8")
install.packages("R2jags")
install.packages("assertthat")
install.packages("ggplot2")
install.packages("gsl")
install.packages("gsl",type="source")
data_path<-"/Users/rafael/Dropbox/artigos/Meusartigos/IAA-WGC/GLMs/Simulation/data/"
Biffi_data<-read.table(file=paste(data_path,"Biffi2014.csv",sep=""),
header=TRUE)
Biffi_data$fstar<-Biffi_data$Mstar/Biffi_data$Mdm
Biffi_data$fgas<-Biffi_data$Mgas/Biffi_data$Mdm
Biffi_data[1,]
Biffi_data$star.gas<-Biffi_data$Mstar/Biffi_data$Mgas
summary(Biffi_data)
Biffi_data<-read.table(file=paste(data_path,"Biffi2014.csv",sep=""),
header=TRUE)
#Biffi_data_original<-Biffi_data
# Problem 1: xmol, Z, SFR. SFR is the response variable
#Biffi_data<-Biffi_data[,c("SFR","Xmol","Z")]
Biffi_data$Mstar<-1e10*Biffi_data$Mstar
Biffi_data$SFR<-1e10*Biffi_data$SFR
Biffi_data$fstar<-Biffi_data$Mstar/Biffi_data$Mdm
Biffi_data$fgas<-Biffi_data$Mgas/Biffi_data$Mdm
Biffi_data$star.gas<-Biffi_data$Mstar/Biffi_data$Mgas
summary(Biffi_data)
sd(Biffi_data)
sd(Biffi_data$Mdm)
mean(Biffi_data$Mdm)
sd(Biffi_data$Mdm)
sd(Biffi_data$Mgas)
sd(Biffi_data$Mstar)
sd(Biffi_data$SFR)
sd(Biffi_data$Z)
sd(Biffi_data$xmol)
sd(Biffi_data$Xmol)
sd(Biffi_data$fgas)
sd(Biffi_data$fstar)
sd(Biffi_data$star.gas)
install.packages("boot")
install.packages("arm")
install.packages("reshape2")
install.packages("reshape")
install.packages("plyr")
install.packages("COUNT")
install.packages("MCMCpack")
install.packages("stargazer")
install.packages("pROC")
install.packages("scales")
install.packages("SDMTools")
install.packages("grDevices")
install.packages("grDevices")
install.packages("grDevices")
install.packages("grDevices")
install.packages("grDevices")
install.packages("grDevices")
exp(5.9)
365/(1+365)
library(R2jags)
library(COUNT)
data(rwm1984)
R84 <- rwm1984
R84$cdoc <- R84$docvis
### JAGS
### ======================================================
K <- 1
win.data <- list(Y    = R84$outwork,
N    = nrow(R84),
cdoc   = R84$cdoc,
K=1,
LogN = log(nrow(R84))
)
sink("GLM.txt")
cat("
model{
#1. Priors
beta.0 ~ dt(0, 1/10^2, 1)
beta.1~dt(0, 1, 1)
#2. Likelihood
for (i in 1:N){
Y[i] ~ dbern(p[i])
logit(p[i]) <- max(-20, min(20, eta[i]))
eta[i]      <- beta.0+beta.1*cdoc[i]
#    cdoc[i]~dbeta(34,14.5)
LLi[i] <- Y[i] * log(p[i]) +
(1 - Y[i]) * log(1 - p[i])
}
LogL <- sum(LLi[1:N])
AIC <- -2 * LogL + 2 * K
BIC <- -2 * LogL + LogN * K
}
",fill = TRUE)
sink()
# INITIAL VALUES - BETAS AND SIGMAS
inits <- function () {
list(
beta.0  = 0.1,beta.1=0.1
)  }
params <- c("beta.0","beta.1","LogL", "AIC", "BIC")
# JAGs
J0 <- jags(data = win.data,
inits = inits,
parameters = params,
model.file = "GLM.txt",
n.thin = 10,
n.chains = 3,
n.burnin = 40000,
n.iter   = 50000)
J0
1/2.5^2
2.5
1/(2.5^2)
cat("
model{
#1. Priors
beta.0 ~ dt(0, 0.16, 1)
beta.1~dt(0, 0.16, 1)
#2. Likelihood
for (i in 1:N){
Y[i] ~ dbern(p[i])
logit(p[i]) <- max(-20, min(20, eta[i]))
eta[i]      <- beta.0+beta.1*cdoc[i]
#    cdoc[i]~dbeta(34,14.5)
LLi[i] <- Y[i] * log(p[i]) +
(1 - Y[i]) * log(1 - p[i])
}
LogL <- sum(LLi[1:N])
AIC <- -2 * LogL + 2 * K
BIC <- -2 * LogL + LogN * K
}
",fill = TRUE)
sink()
# INITIAL VALUES - BETAS AND SIGMAS
inits <- function () {
list(
beta.0  = 0.1,beta.1=0.1
)  }
params <- c("beta.0","beta.1","LogL", "AIC", "BIC")
# JAGs
J0 <- jags(data = win.data,
inits = inits,
parameters = params,
model.file = "GLM.txt",
n.thin = 10,
n.chains = 3,
n.burnin = 40000,
n.iter   = 50000)
J0
win.data <- list(Y    = R84$outwork,
N    = nrow(R84),
X    = X,
K    = K,
LogN = log(nrow(R84)),
b0   = rep(0, K),
B0   = diag(0.00001, K)
)
library(R2jags)
library(COUNT)
data(rwm1984)
R84 <- rwm1984
R84$cage <- R84$age - mean(R84$age)
R84$cdoc <- R84$docvis - mean(R84$docvis)
X <- model.matrix(~ cdoc + female + kids + cage,
data = R84)
K <- ncol(X)
win.data <- list(Y    = R84$outwork,
N    = nrow(R84),
X    = X,
K    = K,
LogN = log(nrow(R84)),
b0   = rep(0, K),
B0   = diag(0.00001, K)
)
sink("GLM.txt")
diag(0.00001, K)
diag(0.00001, 5)
B0   = diag(0.00001, K)
B0
diag(0.00001, 3)
nu = rep(1,K)
nu[]
library(R2jags)
library(COUNT)
data(rwm1984)
R84 <- rwm1984
R84$cage <- R84$age - mean(R84$age)
R84$cdoc <- R84$docvis - mean(R84$docvis)
X <- model.matrix(~ cdoc + female + kids + cage,
data = R84)
K <- ncol(X)
win.data <- list(Y    = R84$outwork,
N    = nrow(R84),
X    = X,
K    = K,
LogN = log(nrow(R84)),
b0   = rep(0, K),
B0   = diag(1/(2.5^2), K),
nu = rep(1,K)
)
sink("GLM.txt")
cat("
model{
#1. Priors
#    beta  ~ dmnorm(b0[], B0[,])
beta  ~ dt(b0[], B0[,],nu[])
#2. Likelihood
for (i in 1:N){
Y[i] ~ dbern(p[i])
logit(p[i]) <- max(-20, min(20, eta[i]))
eta[i]      <- inprod(beta[], X[i,])
LLi[i] <- Y[i] * log(p[i]) +
(1 - Y[i]) * log(1 - p[i])
}
LogL <- sum(LLi[1:N])
AIC <- -2 * LogL + 2 * K
BIC <- -2 * LogL + LogN * K
}
",fill = TRUE)
sink()
# INITIAL VALUES - BETAS AND SIGMAS
inits <- function () {
list(
beta  = rnorm(K, 0, 0.1)
)  }
params <- c("beta", "LogL", "AIC", "BIC")
# JAGs
J0 <- jags(data = win.data,
inits = inits,
parameters = params,
model.file = "GLM.txt",
n.thin = 10,
n.chains = 3,
n.burnin = 40000,
n.iter   = 50000)
win.data <- list(Y    = R84$outwork,
N    = nrow(R84),
X    = X,
K    = K,
LogN = log(nrow(R84)),
b0   = rep(0, K),
B0   = rep(1/(2.5^2), K),
nu = rep(1,K)
)
sink("GLM.txt")
cat("
model{
#1. Priors
#    beta  ~ dmnorm(b0[], B0[,])
beta  ~ dt(b0[], B0[],nu[])
#2. Likelihood
for (i in 1:N){
Y[i] ~ dbern(p[i])
logit(p[i]) <- max(-20, min(20, eta[i]))
eta[i]      <- inprod(beta[], X[i,])
LLi[i] <- Y[i] * log(p[i]) +
(1 - Y[i]) * log(1 - p[i])
}
LogL <- sum(LLi[1:N])
AIC <- -2 * LogL + 2 * K
BIC <- -2 * LogL + LogN * K
}
",fill = TRUE)
sink()
# INITIAL VALUES - BETAS AND SIGMAS
inits <- function () {
list(
beta  = rnorm(K, 0, 0.1)
)  }
params <- c("beta", "LogL", "AIC", "BIC")
# JAGs
J0 <- jags(data = win.data,
inits = inits,
parameters = params,
model.file = "GLM.txt",
n.thin = 10,
n.chains = 3,
n.burnin = 40000,
n.iter   = 50000)
rep(1/(2.5^2), K)
rep(1/(2.5^2), 5)
rep(2,5)
1+4
1+1
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
Xmx = '2g')
library(h2o)
install.packages("h2o")
library(h2o)
## Start a local cluster with 2GB RAM
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
Xmx = '2g')
dat <- BreastCancer[, -1]  # remove the ID column
dat_h2o <- as.h2o(localH2O, dat, key = 'dat')
## Import MNIST CSV as H2O
dat_h2o <- h2o.importFile(localH2O, path = ".../mnist_train.csv")
dat_h2o
dat
BreastCancer[, -1]
localH2O
library(h2o)
localH2O = h2o.init()
irisPath = system.file("extdata", "iris.csv", package = "h2o")
iris.hex = h2o.importFile(localH2O, path = irisPath)
h2o.deeplearning(x = 1:4, y = 5, data = iris.hex, activation = "Tanh",
hidden = c(10, 10), epochs = 5)
data.hex = h2o.importFile(
localH2O,
path = "https://raw.github.com/0xdata/h2o/master/smalldata/bank-additional-full.csv",
key = "data.hex")
myX = 1:20
myY="y"
my.dl = h2o.deeplearning(x=myX,y=myY,data=data.hex,classification=T,activation="Tanh",
hidden=c(10,10,10),epochs=12,variable_importances=T)
dl.VI =my.dl@model$varimp
print(dl.VI)
dl.VI
iris.hex
localH2O
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
Xmx = '16g')
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g')
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=4)
localH2O
h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=4)
library(h2o)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=-1)
irisPath = system.file("extdata", "iris.csv", package = "h2o")
iris.hex = h2o.importFile(localH2O, path = irisPath)
h2o.deeplearning(x = 1:4, y = 5, data = iris.hex, activation = "Tanh",
hidden = c(10, 10), epochs = 5)
h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=-1)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '32g',nthreads=-1)
irisPath = system.file("extdata", "iris.csv", package = "h2o")
iris.hex = h2o.importFile(localH2O, path = irisPath)
h2o.deeplearning(x = 1:4, y = 5, data = iris.hex, activation = "Tanh",
hidden = c(10, 10), epochs = 5)
install.packages("rmongodb")
library(rmongodb)
mongo = mongo.create(host = "localhost")
mongo.is.connected(mongo)
mongo.get.databases(mongo)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/NB_GCs/Models_each_predictor")
#Poisson and NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Function to allow parse labels in facet_wrap
facet_wrap_labeller <- function(gg.plot,labels=NULL) {
#works with R 3.0.1 and ggplot2 0.9.3.1
require(gridExtra)
g <- ggplotGrob(gg.plot)
gg <- g$grobs
strips <- grep("strip_t", names(gg))
for(ii in seq_along(labels))  {
modgrob <- getGrob(gg[[strips[ii]]], "strip.text",
grep=TRUE, global=TRUE)
gg[[strips[ii]]]$children[[modgrob$name]] <- editGrob(modgrob,label=labels[ii])
}
g$grobs <- gg
class(g) = c("arrange", "ggplot",class(g))
g
}
give.n <- function(x){
return(c(y = 0.5, label = length(x)))
# experiment with the multiplier to find the perfect position
}
################
# Script starts here
# Read data
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
N = nrow(GCS)
######## NB with errors ########################################################
MBHx = seq(from = 0.95 * min(GCS$MBH),
to = 1.05 * max(GCS$MBH),
length.out = 500)
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
errMBH = upMBH,
MBHx = MBHx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
# Hyperpriors
#meanx ~ dgamma(30,3)
#varx ~ dgamma(2,1)
#meanx ~ dgamma(85,10)
#varx ~ dgamma(2,1)
meanx ~ dgamma(0.01,0.01)
varx ~ dgamma(0.01,0.01)
for (i in 1:N){
#MBHtrue[i]~dunif(5,12)
# MBHtrue[i]~dnorm(8,0.000001) # this would be sensible too
#MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)T(6,11)
MBHtrue[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
MBH[i]~dnorm(MBHtrue[i],1/errMBH[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MBHtrue[i]
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MBHtrue[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MBHx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
px[j]<-size/(size+mux[j])
prediction.NBx[j]~dnegbin(px[j],size)
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","MBHtrue","Fit","New","prediction.NBx")
#inits1<-function(){list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))}
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=30000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
gelman.diag(jagssamples.nb)
gelman.plot(jagssamples.nb)
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
install.packages("XML")
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
require(XML)
xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
require(XML)
data <- xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML")
xml_data <- xmlToList(data)
?htmlParse
xmlParse("http://forecast.weather.gov/MapClick.php?lat=29.803&lon=-82.411&FcstType=digitalDWML",isHTML = TRUE)
fileName <- system.file("exampleData", "test.xml", package="XML")
xmlTreeParse(fileName)
