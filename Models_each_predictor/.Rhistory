sig_e_true[i] ~ dgamma(meanx^2/varx,meanx/varx)
}
# Likelihood function
for (i in 1:N){
sig_e[i]~dnorm(sig_e_true[i],1/err_sig_e[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*sig_e_true[i]
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*sig_e_true[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*sig_ex[j]
log(mux[j])<-max(-20,min(20,etax[j]))
px[j]<-size/(size+mux[j])
prediction.NBx[j]~dnegbin(px[j],size)
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","prediction.NB","sig_e_true","Fit","New","prediction.NBx")
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=30000,
summarise=FALSE,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
#update(jags.neg3, 10000)
sig_e_true<-summary(as.mcmc.list(jags.neg,vars="sig_e_true"),quantiles=0.5)
#pred.NBerr<-summary(as.mcmc.list(jagssamples.nb3$prediction.NB),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
#pred.NB2err<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,sig_e_true=sig_e_true$quantiles,sig_e=GCS$sig_e,mean=pred.NBerr$statistics[,1],lwr1=pred.NBerr$quantiles[,3],lwr2=pred.NBerr$quantiles[,2],lwr3=pred.NBerr$quantiles[,1],upr1=pred.NBerr$quantiles[,5],upr2=pred.NBerr$quantiles[,6],upr3=pred.NBerr$quantiles[,7])
pred.NBerrx<-summary(as.mcmc.list(jags.neg, vars="prediction.NBx"),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.NB2errx<-data.frame(sig_ex=sig_ex,mean=pred.NBerrx$statistics[,1],lwr1=pred.NBerrx$quantiles[,3],lwr2=pred.NBerrx$quantiles[,2],lwr3=pred.NBerrx$quantiles[,1],upr1=pred.NBerrx$quantiles[,5],upr2=pred.NBerrx$quantiles[,6],upr3=pred.NBerrx$quantiles[,7])
N_low<-GCS$N_GC-N_err
N_low[N_low<0]<-0
asinh_trans <- function(){
trans_new(name = 'asinh', transform = function(x) asinh(x),
inverse = function(x) sinh(x))
}
CairoPDF("..//Figures/sig_e.pdf",height=8,width=9)
ggplot(GCS,aes(x=sig_e,y=N_GC))+
geom_ribbon(data=pred.NB2errx,aes(x=sig_ex,y=mean,ymin=lwr1, ymax=upr1), alpha=0.45, fill="gray",method = "loess") +
geom_ribbon(data=pred.NB2errx,aes(x=sig_ex,y=mean,ymin=lwr2, ymax=upr2), alpha=0.35, fill="gray",method = "loess") +
geom_ribbon(data=pred.NB2errx,aes(x=sig_ex,y=mean,ymin=lwr3, ymax=upr3), alpha=0.25, fill="gray",method = "loess") +
geom_point(aes(colour=Type,shape=Type),size=3.25,alpha=0.8)+
geom_errorbar(guide="none",aes(colour=Type,ymin=N_low,ymax=N_GC+N_err),alpha=0.7,width=0.05)+
geom_errorbarh(guide="none",aes(colour=Type,xmin=sig_e-GCS$err_sig_e,
xmax=sig_e+err_sig_e),alpha=0.7,height=0.05)+
geom_line(data=pred.NB2errx,aes(x=sig_ex,y=mean),colour="gray25",linetype="dashed",size=1.2)+
scale_y_continuous(trans = 'asinh',breaks=c(0,10,100,1000,10000,100000),labels=c("0",expression(10^1),expression(10^2),
expression(10^3),expression(10^4),expression(10^5)))+
scale_colour_gdocs()+
scale_shape_manual(values=c(19,2,8,10))+
#  theme_economist_white(gray_bg = F, base_size = 11, base_family = "sans")+
theme_hc()+
ylab(expression(N[GC]))+
xlab(expression(sigma~(km/s)))+theme(legend.position="top",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=25))
dev.off()
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/COINtoolbox/NB_GCs/Models_each_predictor")
#Poisson and NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Function to allow parse labels in facet_wrap
facet_wrap_labeller <- function(gg.plot,labels=NULL) {
#works with R 3.0.1 and ggplot2 0.9.3.1
require(gridExtra)
g <- ggplotGrob(gg.plot)
gg <- g$grobs
strips <- grep("strip_t", names(gg))
for(ii in seq_along(labels))  {
modgrob <- getGrob(gg[[strips[ii]]], "strip.text",
grep=TRUE, global=TRUE)
gg[[strips[ii]]]$children[[modgrob$name]] <- editGrob(modgrob,label=labels[ii])
}
g$grobs <- gg
class(g) = c("arrange", "ggplot",class(g))
g
}
give.n <- function(x){
return(c(y = 0.5, label = length(x)))
# experiment with the multiplier to find the perfect position
}
################
# Script starts here
# Read data
GCS = read.csv(file="..//Dataset//GCs_full.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(MV_T))
#dim(GCS)
N_err<-GCS$N_GC_err
err_MV_T<-GCS$err_MV_T
N = nrow(GCS)
######## NB with errors ########################################################
MV_Tx = seq(from = 1.05 * min(GCS$MV_T),
to = 0.95 * max(GCS$MV_T),
length.out = 500)
jags.data <- list(
N_GC = GCS$N_GC,
MV_T = GCS$MV_T,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
err_MV_T = err_MV_T,
MV_Tx = MV_Tx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
#
for (i in 1:N){
MV_T_true[i]~dunif(-26,-10)
}
# Likelihood function
for (i in 1:N){
MV_T[i]~dnorm(MV_T_true[i],1/err_MV_T[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MV_T_true[i]
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MV_T_true[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MV_Tx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
px[j]<-size/(size+mux[j])
prediction.NBx[j]~dnegbin(px[j],size)
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","MV_T_true","Fit","New","prediction.NBx")
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2500,
monitor=c(params),
burnin=20000,
sample=30000,
summarise=FALSE,
thin=5,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
#update(jags.neg, 10000)
#jagssamples.nb <- jags.samples(jags.neg, params, n.iter = 50000)
MV_T_true<-summary(as.mcmc.list(jags.neg,vars="MV_T_true"),quantiles=0.5)
#pred.NBerr<-summary(as.mcmc.list(jagssamples.nb, vars="prediction.NB"),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
#pred.NB2err<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,MV_T_true=MV_T_true$quantiles,MV_T=GCS$MV_T,mean=pred.NBerr$statistics[,1],lwr1=pred.NBerr$quantiles[,3],lwr2=pred.NBerr$quantiles[,2],lwr3=pred.NBerr$quantiles[,1],upr1=pred.NBerr$quantiles[,5],upr2=pred.NBerr$quantiles[,6],upr3=pred.NBerr$quantiles[,7])
pred.NBerrx<-summary(as.mcmc.list(jags.neg, vars="prediction.NBx"),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.NB2errx<-data.frame(MV_Tx=MV_Tx,mean=pred.NBerrx$statistics[,1],lwr1=pred.NBerrx$quantiles[,3],lwr2=pred.NBerrx$quantiles[,2],lwr3=pred.NBerrx$quantiles[,1],upr1=pred.NBerrx$quantiles[,5],upr2=pred.NBerrx$quantiles[,6],upr3=pred.NBerrx$quantiles[,7])
N_low<-GCS$N_GC-N_err
N_low[N_low<0]<-0
asinh_trans <- function(){
trans_new(name = 'asinh', transform = function(x) asinh(x),
inverse = function(x) sinh(x))
}
cairo_pdf("..//Figures/M_Vxfull.pdf",height=8,width=9)
ggplot(GCS,aes(x=MV_T,y=N_GC))+
geom_ribbon(data=pred.NB2errx,aes(x=MV_Tx,y=mean,ymin=lwr1, ymax=upr1), alpha=0.45, fill="gray",method = "loess") +
geom_ribbon(data=pred.NB2errx,aes(x=MV_Tx,y=mean,ymin=lwr2, ymax=upr2), alpha=0.35, fill="gray",method = "loess") +
geom_ribbon(data=pred.NB2errx,aes(x=MV_Tx,y=mean,ymin=lwr3, ymax=upr3), alpha=0.25, fill="gray",method = "loess") +
geom_point(aes(colour=Type,shape=Type),size=3.25,alpha=0.8)+
geom_errorbar(guide="none",aes(colour=Type,ymin=N_low,ymax=N_GC+N_err),alpha=0.7,width=0.05)+
geom_errorbarh(guide="none",aes(colour=Type,xmin=MV_T-GCS$err_MV_T,
xmax=MV_T+err_MV_T),alpha=0.7,height=0.05)+
geom_line(data=pred.NB2errx,aes(x=MV_Tx,y=mean),colour="gray25",linetype="dashed",size=1.2)+
scale_y_continuous(trans = 'asinh',breaks=c(0,10,100,1000,10000,100000),labels=c("0",expression(10^1),expression(10^2),
expression(10^3),expression(10^4),expression(10^5)))+
scale_colour_gdocs()+
scale_shape_manual(values=c(19,2,8,10))+scale_x_reverse()+
#  theme_economist_white(gray_bg = F, base_size = 11, base_family = "sans")+
theme_hc()+
ylab(expression(N[GC]))+
xlab(expression(M[V]))+theme(legend.position="top",plot.title = element_text(hjust=0.5),
axis.title.y=element_text(vjust=0.75),
axis.title.x=element_text(vjust=-0.25),
text = element_text(size=25))
dev.off()
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/COINtoolbox/NB_GCs/Models_each_predictor")
#Poisson and NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
# Function to allow parse labels in facet_wrap
facet_wrap_labeller <- function(gg.plot,labels=NULL) {
#works with R 3.0.1 and ggplot2 0.9.3.1
require(gridExtra)
g <- ggplotGrob(gg.plot)
gg <- g$grobs
strips <- grep("strip_t", names(gg))
for(ii in seq_along(labels))  {
modgrob <- getGrob(gg[[strips[ii]]], "strip.text",
grep=TRUE, global=TRUE)
gg[[strips[ii]]]$children[[modgrob$name]] <- editGrob(modgrob,label=labels[ii])
}
g$grobs <- gg
class(g) = c("arrange", "ggplot",class(g))
g
}
give.n <- function(x){
return(c(y = 0.5, label = length(x)))
# experiment with the multiplier to find the perfect position
}
################
# Script starts here
# Read data
GCS = read.csv(file="..//Dataset//GCs.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(Mdyn)) # 1 removed
dim(GCS)
N_err<-GCS$N_GC_err
lowMBH<-GCS$lowMBH
upMBH<-GCS$upMBH
err_sig_e<-GCS$err_sig_e
# Poisson model
model.pois<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Likelihood function
for (i in 1:N){
eta[i]<-beta.0+beta.1*MBH[i]
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
N_GC[i]~dpois(mu[i])
# Prediction
prediction.pois[i]~dpois(mu[i])
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","prediction.pois","PRes")
jags.pois<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.pois),
n.chains = 3,
n.adapt=1000
)
update(jags.pois, 20000)
posterior.pois <- coda.samples(jags.pois, params, n.iter = 50000)
jagssamples <- jags.samples(jags.pois, params, n.iter = 50000)
pred.pois<-summary(as.mcmc.list(jagssamples$prediction.pois),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.pois2<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,MBH=GCS$MBH,mean=pred.pois$quantiles[,4],lwr1=pred.pois$quantiles[,3],lwr2=pred.pois$quantiles[,2],lwr3=pred.pois$quantiles[,1],upr1=pred.pois$quantiles[,5],upr2=pred.pois$quantiles[,6],upr3=pred.pois$quantiles[,7])
model.pois<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Likelihood function
for (i in 1:N){
eta[i]<-beta.0+beta.1*MBH[i]
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
N_GC[i]~dpois(mu[i])
# Prediction
prediction.pois[i]~dpois(mu[i])
# Discrepancy measures
YNew[i] ~ dpois(mu[i])
expY[i] <- mu[i]
varY[i] <- mu[i]
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
}
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","prediction.pois","PRes")
jags.pois<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.pois),
n.chains = 3,
n.adapt=1000
)
model.pois<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Likelihood function
for (i in 1:N){
eta[i]<-beta.0+beta.1*MBH[i]
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
N_GC[i]~dpois(mu[i])
# Prediction
prediction.pois[i]~dpois(mu[i])
# Discrepancy measures
YNew[i] ~ dpois(mu[i])
expY[i] <- mu[i]
varY[i] <- mu[i]
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","prediction.pois","PRes")
jags.pois<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.pois),
n.chains = 3,
n.adapt=1000
)
update(jags.pois, 20000)
posterior.pois <- coda.samples(jags.pois, params, n.iter = 50000)
jagssamples <- jags.samples(jags.pois, params, n.iter = 50000)
pred.pois<-summary(as.mcmc.list(jagssamples$prediction.pois),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.pois2<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,MBH=GCS$MBH,mean=pred.pois$quantiles[,4],lwr1=pred.pois$quantiles[,3],lwr2=pred.pois$quantiles[,2],lwr3=pred.pois$quantiles[,1],upr1=pred.pois$quantiles[,5],upr2=pred.pois$quantiles[,6],upr3=pred.pois$quantiles[,7])
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
errN_GC = GCS$N_GC_err,
N = nrow(GCS)
)
# Poisson model
model.pois<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Likelihood function
for (i in 1:N){
eta[i]<-beta.0+beta.1*MBH[i]
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
N_GC[i]~dpois(mu[i])
# Prediction
prediction.pois[i]~dpois(mu[i])
# Discrepancy measures
YNew[i] ~ dpois(mu[i])
expY[i] <- mu[i]
varY[i] <- mu[i]
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","prediction.pois","PRes")
jags.pois<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.pois),
n.chains = 3,
n.adapt=1000
)
jags.data <- list(
N_GC = GCS$N_GC,
MBH = GCS$MBH,
N = nrow(GCS)
)
# Poisson model
model.pois<-"model{
#Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Likelihood function
for (i in 1:N){
eta[i]<-beta.0+beta.1*MBH[i]
log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
N_GC[i]~dpois(mu[i])
# Prediction
prediction.pois[i]~dpois(mu[i])
# Discrepancy measures
YNew[i] ~ dpois(mu[i])
expY[i] <- mu[i]
varY[i] <- mu[i]
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
}"
#inits<-list(beta.0=coefficients(glm.pois)[1],beta.1=coefficients(glm.pois)[2])
inits<-list(beta.0=0,beta.1=0)
params<-c("beta.0","beta.1","prediction.pois","PRes")
jags.pois<-jags.model(
data = jags.data,
inits = inits,
textConnection(model.pois),
n.chains = 3,
n.adapt=1000
)
update(jags.pois, 20000)
posterior.pois <- coda.samples(jags.pois, params, n.iter = 50000)
jagssamples <- jags.samples(jags.pois, params, n.iter = 50000)
pred.pois<-summary(as.mcmc.list(jagssamples$prediction.pois),quantiles=c(0.005,0.025,0.25,0.5,0.75,0.975, 0.995))
pred.pois2<-data.frame(Type=GCS$Type,NGC=GCS$N_GC,MBH=GCS$MBH,mean=pred.pois$quantiles[,4],lwr1=pred.pois$quantiles[,3],lwr2=pred.pois$quantiles[,2],lwr3=pred.pois$quantiles[,1],upr1=pred.pois$quantiles[,5],upr2=pred.pois$quantiles[,6],upr3=pred.pois$quantiles[,7])
require(scales)
Pres<-summary(as.mcmc.list(jags.neg$PRes),quantiles=0.5)$quantiles
Dipersion = sum(Pres^2)/(N-2)# beta.0, beta.1, 2 parameters
jags.neg
jags.pois$PRes
jags.pois
as.mcmc.list(jags.pois)
as.mcmc.list(posterior.pois )
summary(as.mcmc.list(posterior.pois )$PRes,quantiles=0.5)$quantiles
summary(as.mcmc.list(posterior.pois$PRes),quantiles=0.5)$quantiles
posterior.pois$PRes
jagssamples$PRes
Pres<-summary(as.mcmc.list(jagssamples$PRes),quantiles=0.5)$quantiles
Dipersion = sum(Pres^2)/(N-2)# beta.0, beta.1, 2 parameters
N = nrow(GCS)
Dipersion = sum(Pres^2)/(N-2)# beta.0, beta.1, 2 parameters
Dipersion
